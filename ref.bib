@String { aaai        = {AAAI Conference on Artificial Intelligence (AAAI)} }
@String { aamas       = {International Conference on Autonomous Agents and Multiagent Systems (AAMAS)} }
@String { acc         = {American Control Conference (ACC)} }
@String { ai          = {Artificial Intelligence} }
@String { aiaa_info   = {AIAA Infotech@Aerospace Conference} }
@String { aiaa_jacic  = {Journal of Aerospace Computing, Information, and Communication} }
@String { allerton    = {Allerton Conference on Communication, Control, and Compution} }
@String { atio        = {AIAA Aviation Technology, Integration, and Operations Conference (ATIO)} }
@String { cacm        = {Communications of the ACM} }
@String { cdc         = {IEEE Conference on Decision and Control (CDC)} }
@String { cvpr        = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)} }
@String { dasc        = {Digital Avionics Systems Conference (DASC)} }
@String { ecml        = {European Conference on Machine Learning (ECML)} }
@String { gnc         = {AIAA Guidance, Navigation, and Control Conference (GNC)} }
@String { icaart      = {International Conference on Agents and Artificial Intelligence (ICAART)} }
@String { icaps       = {International Conference on Automated Planning and Scheduling (ICAPS)} }
@String { icassp      = {International Conference on Acoustics, Speech, and Signal Processing (ICASSP)} }
@String { icml        = {International Conference on Machine Learning (ICML)} }
@String { icmla       = {International Conference on Machine Learning and Applications (ICMLA)} }
@String { icra        = {IEEE International Conference on Robotics and Automation (ICRA)} }
@String { icslp       = {International Conference on Spoken Language Processing (ICSLP)} }
@String { ieee_csm    = {IEEE Control Systems Magazine} }
@String { ieee_j_ac   = {IEEE Transactions on Automatic Control} }
@String { ieeeaero    = {IEEE Aerospace Conference} }
@String { ieeeciaig   = {IEEE Transactions on Computational Intelligence and AI in Games} }
@String { ieeecst     = {IEEE Transactions on Control Systems Technology} }
@String { ieeetac     = {IEEE Transactions on Automatic Control} }
@String { ieeetsp     = {IEEE Transactions on Signal Processing} }
@String { ijcai       = {International Joint Conference on Artificial Intelligence (IJCAI)} }
@String { interspeech = {Annual Conference of the International Speech Communication Association (INTERSPEECH)} }
@String { iros        = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)} }
@String { itsc        = {IEEE International Conference on Intelligent Transportation Systems (ITSC)} }
@String { jair        = {Journal of Artificial Intelligence Research} }
@String { jgcd        = {AIAA Journal of Guidance, Control, and Dynamics} }
@String { jmlr        = {Journal of Machine Learning Research} }
@String { jota        = {Journal of Optimization Theory and Applications} }
@String { lion        = {Learning and Intelligent Optimization (LION)} }
@String { mit         = {Massachusetts Institute of Technology} }
@String { mitaa       = {Massachusetts Institute of Technology, Department of Aeronautics and Astronautics} }
@String { mitee       = {Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science} }
@String { mitme       = {Massachusetts Institute of Technology, Department of Mechanical Engineering} }
@String { mor         = {Mathematics of Operations Research} }
@String { nips        = {Advances in Neural Information Processing Systems (NIPS)} }
@String { or          = {Operations Research} }
@String { rss         = {Robotics: Science and Systems} }
@String { sigcomm     = {ACM Special Interest Group on Data Communication (SIGCOMM)} }
@String { suaa        = {Stanford University, Department of Aeronautics and Astronautics} }
@String { suee        = {Stanford University, Department of Electrical Engineering} }
@String { sume        = {Stanford University, Department of Mechanical Engineering} }
@String { tac         = {IEEE Transactions on Automatic Control} }
@String { tacas       = {International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS)} }
@String { taes        = {IEEE Transactions on Aerospace and Electronic Systems} }
@String { uai         = {Conference on Uncertainty in Artificial Intelligence (UAI)} }

@InProceedings{silver2010pomcp,
  author =    {David Silver and Joel Veness},
  title =     {{M}onte-{C}arlo Planning in Large {POMDP}s},
  booktitle = nips,
  year =      {2010}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{couetoux2011double,
  address = {Rome, Italy},
  annote = {double progressive widening},
  author = {Cou\"{e}toux, A. and Hoock, J.-B. and Sokolovska, N. and Teytaud, O. and Bonnard, N.},
  booktitle = {Learning and Intelligent Optimization},
  mendeley-groups = {UAVCAS,POMDPs,MDPs},
  title = {Continuous Upper Confidence Trees},
  year = {2011}
}

@Book{kochenderfer2015decision,
  title =         {Decision Making Under Uncertainty: Theory and Application},
  publisher =     {{MIT} Press},
  year =          {2015},
  author =        {Mykel J. Kochenderfer}
}


@article{kaelbling1998planning,
  author = {{L}. {P}. {K}aelbling and {M}. {L}. {L}ittman and {A}.{R}. {C}assandra},
  title = {Planning and acting in partially observable stochastic domains},
  journal = ai,
  year = {1998},
  volume = {101},
  pages = {99--134},
}

# below this line unchecked

@inproceedings{littman1995learning,
  title={Learning policies for partially observable environments: Scaling up},
  author={Littman, Michael L. and Cassandra, Anthony R. and Kaelbling, Leslie Pack},
  booktitle=icml,
  year={1995},
}

@book{thrun2005probabilistic,
  title={Probabilistic Robotics},
  author={Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
  year={2005},
  publisher={{MIT} Press}
}

@article{browne2012survey,
  title={A survey of {M}onte {C}arlo tree search methods},
  author={Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  journal={{IEEE} Transactions on Computational Intelligence and {AI} in games},
  volume={4},
  number={1},
  pages={1--43},
  year={2012},
}

@inproceedings{thrun1999monte,
  title={{M}onte {C}arlo {POMDP}s.},
  author={Thrun, Sebastian},
  booktitle=nips,
  volume={12},
  pages={1064--1070},
  year={1999}
}

@inproceedings{kurniawati2008sarsop,
  title={{SARSOP}: Efficient Point-Based {POMDP} Planning by Approximating Optimally Reachable Belief Spaces.},
  author={Kurniawati, Hanna and Hsu, David and Lee, Wee Sun},
  booktitle={Robotics: Science and Systems},
  year={2008},
  address={Zurich, Switzerland.}
}

@article{bai2014integrated,
  title={Integrated perception and planning in the continuous space: A {POMDP} approach},
  author={Bai, Haoyu and Hsu, David and Lee, Wee Sun},
  journal={International Journal of Robotics Research},
  volume={33},
  number={9},
  pages={1288--1302},
  year={2014},
  address={London, England}
}

@incollection{bai2010monte,
  title={{M}onte {C}arlo value iteration for continuous-state {POMDP}s},
  author={Bai, Haoyu and Hsu, David and Lee, Wee Sun and Ngo, Vien A.},
  booktitle={Algorithmic foundations of robotics {IX}},
  pages={175--191},
  year={2010},
  publisher={Springer}
}

@inproceedings{brechtel2013solving,
  title={Solving Continuous {POMDP}s: Value Iteration with Incremental Learning of an Efficient Space Representation},
  author={Brechtel, Sebastian and Gindele, Tobias and Dillmann, R{\"u}diger},
  booktitle=icml,
  pages={370--378},
  year={2013}
}

@article{ross2008online,
  title={Online planning algorithms for {POMDP}s},
  author={Ross, St{\'e}phane and Pineau, Joelle and Paquet, S{\'e}bastien and Chaib-Draa, Brahim},
  journal={Journal of Artificial Intelligence Research},
  volume={32},
  pages={663--704},
  year={2008}
}

@inproceedings{somani2013despot,
  title={{DESPOT}: Online {POMDP} planning with regularization},
  author={Somani, Adhiraj and Ye, Nan and Hsu, David and Lee, Wee Sun},
  booktitle=nips,
  pages={1772--1780},
  year={2013}
}

@incollection{kurniawati2016online,
  title={An online {POMDP} solver for uncertainty planning in dynamic environment},
  author={Kurniawati, Hanna and Yadav, Vinay},
  booktitle={Robotics Research},
  pages={611--629},
  year={2016},
  publisher={Springer}
}

@inproceedings{hoey2005solving,
  title={Solving {POMDP}s with continuous or large discrete observation spaces},
  author={Hoey, Jesse and Poupart, Pascal},
  booktitle=ijcai,
  pages={1332--1338},
  year={2005}
}

@inproceedings{melchior2007particle,
  title={Particle {RRT} for path planning with uncertainty},
  author={Melchior, Nik A and Simmons, Reid},
  booktitle=icra,
  year={2007},
}

inproceedings{melchior2007particle,
  title={Particle {RRT} for path planning with uncertainty},
  author={Melchior, Nik A and Simmons, Reid},
  booktitle=icra,
  pages={1617--1624},
  year={2007},
}

@article{prentice2009belief,
  title={The belief roadmap: Efficient planning in belief space by factoring the covariance},
  author={Prentice, Samuel and Roy, Nicholas},
  journal={International Journal of Robotics Research},
  volume={28},
  number={11-12},
  pages={1448--1465},
  year={2009},
  address={London, England}
}

@inproceedings{platt2010belief,
  title={Belief space planning assuming maximum likelihood observations},
  author={Platt, Jr., Robert and Tedrake, Russ and Kaelbling, Leslie and Lozano-Perez, Tomas},
  booktitle=rss,
  year={2010}
}

@inproceedings{agha2011firm,
  title={{FIRM}: Feedback controller-based information-state roadmap - a framework for motion planning under uncertainty},
  author={Agha-Mohammadi, Ali-Akbar and Chakravorty, Suman and Amato, Nancy M},
  booktitle=iros,
  year={2011},
}

inproceedings{agha2011firm,
  title={{FIRM}: Feedback controller-based information-state roadmap - a framework for motion planning under uncertainty},
  author={Agha-Mohammadi, Ali-Akbar and Chakravorty, Suman and Amato, Nancy M},
  booktitle=iros,
  pages={4284--4291},
  year={2011},
}

@inproceedings{bry2011rapidly,
  title={Rapidly-exploring random belief trees for motion planning under uncertainty},
  author={Bry, Adam and Roy, Nicholas},
  booktitle=icra,
  pages={723--730},
  year={2011},
}

@mastersthesis{pas2012simulation,
  title={Simulation Based Planning for Partially Observable Markov Decision Processes with Continuous Observation Spaces},
  author={Pas, Andreas},
  year={2012},
  school={Maastricht University}
}

@article{van2012motion,
  title={Motion planning under uncertainty using iterative local optimization in belief space},
  author={Van Den Berg, Jur and Patil, Sachin and Alterovitz, Ron},
  journal={International Journal of Robotics Research},
  volume={31},
  number={11},
  pages={1263--1278},
  year={2012},
}

@article{guez2013scalable,
  title={Scalable and efficient Bayes-adaptive reinforcement learning based on Monte-Carlo tree search},
  author={Guez, Arthur and Silver, David and Dayan, Peter},
  journal={Journal of Artificial Intelligence Research},
  volume={48},
  pages={841--883},
  year={2013}
}

@article{bojarski2016end,
  author    = {Mariusz Bojarski and
               Davide Del Testa and
               Daniel Dworakowski and
               Bernhard Firner and
               Beat Flepp and
               Prasoon Goyal and
               Lawrence D. Jackel and
               Mathew Monfort and
               Urs Muller and
               Jiakai Zhang and
               Xin Zhang and
               Jake Zhao and
               Karol Zieba},
  title     = {End to End Learning for Self-Driving Cars},
  journal   = {CoRR},
  volume    = {abs/1604.07316},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.07316},
  timestamp = {Mon, 02 May 2016 18:22:52 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/BojarskiTDFFGJM16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{goldhoorn2014continuous,
  title={Continuous real time {POMCP} to find-and-follow people by a humanoid service robot},
  author={Goldhoorn, Alex and Garrell, Ana{\'\i}s and Alqu{\'e}zar, Ren{\'e} and Sanfeliu, Alberto},
  booktitle={{IEEE}-{RAS} International Conference on Humanoid Robots},
  year={2014},
}

inproceedings{goldhoorn2014continuous,
  title={Continuous real time {POMCP} to find-and-follow people by a humanoid service robot},
  author={Goldhoorn, Alex and Garrell, Ana{\'\i}s and Alqu{\'e}zar, Ren{\'e} and Sanfeliu, Alberto},
  booktitle={{IEEE}-{RAS} International Conference on Humanoid Robots},
  pages={741--747},
  year={2014},
}

@inproceedings{seiler2015online,
  title={An online and approximate solver for {POMDP}s with continuous action space},
  author={Seiler, Konstantin M. and Kurniawati, Hanna and Singh, Surya P. N.},
  booktitle=icra,
  pages={2290--2297},
  year={2015},
}

@article{indelman2015planning,
  title={Planning in the continuous domain: A generalized belief space approach for autonomous navigation in unknown environments},
  author={Indelman, Vadim and Carlone, Luca and Dellaert, Frank},
  journal={International Journal of Robotics Research},
  volume={34},
  number={7},
  pages={849--882},
  year={2015},
  address={London, England}
}

@inproceedings{morere2016bayesian,
  title={Bayesian Optimisation for solving Continuous State-Action-Observation {POMDP}s},
  author={Morere, Philippe and Marchant, Roman and Ramos, Fabio},
  booktitle=nips,
  year=2016
}

@inproceedings{mansley2011sample,
  title={Sample-Based Planning for Continuous Action {M}arkov Decision Processes},
  author={Mansley, Christopher R. and Weinstein, Ari and Littman, Michael L.},
  booktitle=icaps,
  year={2011}
}

inproceedings{sunberg2017value,
    title={Authors and title withheld to preserve anonymity},
    author={Same Authors, The},
    booktitle={A Conference},
    year={2017}
}

@inproceedings{sunberg2017value,
    title={The Value of Inferring the Internal State of Traffic Participants for Autonomous Freeway Driving},
    author={Sunberg, Zachary N. and Ho, Christopher J. and Kochenderfer, Mykel, J.},
    booktitle=acc,
    year={2017}
}

@inproceedings{auger2013continuous,
  title={Continuous upper confidence trees with polynomial exploration--consistency},
  author={Auger, David and Couetoux, Adrien and Teytaud, Olivier},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={194--209},
  year={2013},
  organization={Springer}
}

@inproceedings{mannor2003cross,
  title={The Cross Entropy Method for Fast Policy Search},
  author={Mannor, Shie and Rubinstein, Reuven and Gat, Yohai},
  booktitle=icml,
  pages={512--519},
  year={2003},
}

url={http://www.aaai.org/Papers/ICML/2003/ICML03-068.pdf}

@inproceedings{dressel2017efficient,
	author = {Louis Dressel and Mykel Kochenderfer},
	title = {Efficient Decision-Theoretic Target Localization},
    booktitle=icaps,
	year = {2017},
	abstract = {Partially observable Markov decision processes (POMDPs) offer a principled approach to control under uncertainty. However, POMDP solvers generally require rewards to depend only on the state and action. This limitation is unsuitable for information-gathering problems, where rewards are more naturally expressed as functions of belief. In this work, we consider target localization, an information-gathering task where an agent takes actions leading to informative observations and a concentrated belief over possible target locations. By leveraging recent theoretical and algorithmic advances, we investigate offline and online solvers that incorporate belief-dependent rewards. We extend SARSOP — a state-of-the-art offline solver — to handle belief-dependent rewards, exploring different reward strategies and showing how they can be compactly represented. We present an improved lower bound that greatly speeds convergence. POMDP-lite, an online solver, is also evaluated in the context of information-gathering tasks. These solvers are applied to control a hexcopter UAV searching for a radio frequency source—a challenging real-world problem.},
	url = {https://www.aaai.org/ocs/index.php/ICAPS/ICAPS17/paper/view/15761/15090}
}

@inproceedings{araya2010pomdp,
title = {A {POMDP} Extension with Belief-dependent Rewards},
author = {Araya, Mauricio and Olivier Buffet and Vincent Thomas and Fran\c{c}cois Charpillet},
booktitle = nips,
year = {2010},
url = {http://papers.nips.cc/paper/3971-a-pomdp-extension-with-belief-dependent-rewards.pdf}
}

@article{egorov2017pomdps,
  author  = {Maxim Egorov and Zachary N. Sunberg and Edward Balaban and Tim A. Wheeler and Jayesh K. Gupta and Mykel J. Kochenderfer},
  title   = {{POMDP}s.jl: A Framework for Sequential Decision Making under Uncertainty},
  journal = jmlr,
  year    = {2017},
  volume  = {18},
  number  = {26},
  pages   = {1-5},
  url     = {http://jmlr.org/papers/v18/16-300.html}
}

@article{fullversion,
     author    = {Zachary N. Sunberg and Mykel J. Kochenderfer},
     title     = {Online algorithms for {POMDP}s with continuous state, action, and observation spaces (extended version)},
     year      = {2018},
     archivePrefix = {arXiv},
     eprint    = {1709.06196},
     note = {\url{https://arxiv.org/abs/1709.06196}}
}

@article{bezanson2017julia,
  title={Julia: A fresh approach to numerical computing},
  author={Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
  journal={SIAM review},
  volume={59},
  number={1},
  pages={65--98},
  year={2017},
  publisher={SIAM}
}
