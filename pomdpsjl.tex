\chapter{POMDPs.jl: A Framework for Sequential Decision Making under Uncertainty} \label{chap:pomdpsjl}

Since exact optimal solutions to POMDPs can rarely be attained, most research into solving realistic problems involves empirical comparison between solution techniques.
Sharing solver software between researchers can greatly improve speed and quality of this work.
Moreover, a consistent and concise framework for representing problems and demonstrating solution techniques is invaluable for POMDP education.
This chapter describes the POMDPs.jl software package created by the Stanford Intelligent Systems Lab (SISL) to make state-of-the-art POMDP solution methods easily accessible to students, researchers, and engineers.
All of the research in \cref{chap:multilane,chap:pomcpow} was conducted using this framework.

The POMDPs.jl package itself is implementation-free, and contains only the interface, however the JuliaPOMDP organization maintains several other packages that provide tools and concrete implementations. For example, the POMDPToolbox package contains a variety of useful tools for representing common distributions, beliefs, policies, etc. and the POMDPModels package contains some simple problem implementations.

\section{Challenges for POMDP-solving software}

A successful POMDP software framework must have, at a minimum, the following attributes: speed, flexibility, and ease of use. Achieving all of these attributes simultaneously is a major challenge.

\subsection{Speed}

Since POMDPs are difficult to solve~\cite{papadimitriou1987complexity}, any computational slowdown such as unnecessary memory allocation or runtime type inference significantly reduces the maximum problem size that the framework can handle.
For this reason, POMDP algorithms must be compiled to efficient processor instructions with low overhead.

\subsection{Flexibility}

The set of problems that can be represented as a POMDP is extremely large and there are many possible characteristics that such problems might have.
A good POMDP software framework should try to accommodate as much of this set as possible.
A few of the most important model characteristics to support are outlined below.

\subsubsection{Partial and full observability}

When studying a POMDP problem, it is almost always important to analyze the underlying fully-observable problem.
Thus, a good POMDP framework should have first-class support for MDPs in addition to POMDPs.

\subsubsection{Continuous and discrete problems}

Some POMDPs have a finite number of states, actions, and observations, i.e. $|\sspace| < \infty$, $|\aspace| < \infty$, and $|\ospace| < \infty$.
However, many real world problems, notably robotics problems, are naturally formulated in spaces with uncountably infinite cardinality, e.g. $\sspace = \reals$, $\aspace = \reals$, and $\ospace = \reals$, multi-dimensional vector spaces, e.g. $\sspace = \reals^6$, or hybrid continuous-discrete spaces.
This means that the framework must not be constrained to use integers for state representation, but should be capable of using a range of structures including floating point numbers and arrays.

\subsubsection{Explicit vs generative model representation}

Some POMDP and MDP solution techniques use the explicit probability distributions $\tdist$ and $\odist$ to solve problems.
Thus, a successful framework must include a way to explicitly specify $\tdist$ and $\odist$.
On the other hand, explicitly specifying $\tdist$ and $\odist$ for many realistic problems is exceedingly difficult and tedious, and specifying a generative model is the only practical way to encode the problem.
Thus, a successful framework must also include generative model support.

\subsubsection{Online and offline solvers}

While some POMDP solution techniques seek exact offline solutions to small problems, many larger problems can only be practically solved online.
Thus a good POMDP framework must have first class support for solving offline and efficiently executing a policy online or executing a planner that does significant computation online.

\subsubsection{Policy representation}

The policies that different solution techniques yield can take a variety of forms.
Exact solution techniques typically attempt to find alpha vectors that encode an optimal policy \cite{kaelbling1998planning,kurniawati2008sarsop}, whereas others use finite state machines \cite{bai2010mcvi}.
Newer methods may use neural networks \cite{karkus2017qmdp} or other structures to store policies, so a successful framework must provide a flexible way to represent all of these structures.

\subsection{Ease of Use}

In addition to being flexible and performant, the framework must be easy to use.
It is possible to make a framework that is performant and flexible but so complex that it will not be adopted or will cause much time to be wasted in understanding and implementation.
For the framework to be considered a success, it must be adopted by the community and serve as an enabler rather than a hindrance to research.

\section{Previous frameworks}

A number of frameworks exist for solving sequential decision problems.
However, most frameworks are written from a reinforcement learning perspective and hence only support either fully observable problems or problems where the state is fully observable, or environments that can generate observations but do not provide access to the Markov state structure of the problem.
Examples from this class are BURLAP~\cite{diuk2008object}, RLPy~\cite{geramifard2015rlpy}, and rllab~\cite{duan2016benchmarking}.
The most closely related frameworks to POMDPs.jl are APPL~\citep{appl}, AI-Toolbox~\citep{aitoolbox}, and ZMDP~\citep{zmdp} in that they explicitly represent the state and partial observability.
\todo{Check if BURLAP and ai toolbox actually do what I say}

APPL is the most widely used and up to date of these POMDP frameworks.
It is written efficiently in C++ and is excellent from a speed perspective.
However, it has several shortcomings in terms of flexibility and ease of use.
First, though all of the solvers in APPL support the POMDPX file format for discrete, explicit problem definitions, flexibility is limited because there is not a unified interface for defining generative models or continuous explicit models.
Second, prototyping problems and solvers in this framework is relatively time consuming and complex, making it difficult to use.
Specifically, the POMDPX file format is based on XML and is difficult for humans to write directly, so, in most cases, custom scripts must be written to create the files, and solvers and generative models written in C++ have higher development time costs than those written in a higher level language.

\todo{Check to make sure there is not a unified distribution}
\todo{Get quote from APPL}

Though much research progress has been made with these frameworks, POMDPs.jl offers several significant improvements.

\section{Architecture}

POMDPs.jl is designed to facilitate communication between different people performing three actions: defining problems, writing solver software, and running simulation experiments.
The same person will often operate in two or even all three of these roles, but will nearly always bring in some tools written by others.

The framework derives its solutions to the challenges outlined above primarily through the use of the Julia language itself \cite{bezanson2017julia}.
Julia is just-in-time compiled using the state-of-the art LLVM compiler framework, giving it speed comparable to traditional compiled languages such as C and C++.
However, unlike other compiled languages, it has many features that make numerical software development easier and faster.
For example, like Python, it is dynamically typed, has a powerful and flexible type system, and uses a modern, convenient syntax with features like list comprehensions, and, like Matlab, it has built-in efficient multidimensional arrays and linear algebra.
The makes meeting the flexibility and ease-of-use goals much easier.

\todo{cite LLVM}
\todo{Make sure Julia is dynamically typed}

This section describes some of the concepts used in the framework before outlining the interface itself.

\subsection{Concepts} \label{sec:concepts}

To fulfill each of the roles mentioned above, a programmer implements one or more classes that concretely represent concepts used to describe POMDP solving.
The problem writer creates a concrete subtype of the \texttt{POMDP} or \texttt{MDP} abstract classes to represent a problem, the simulator writer creates a \texttt{Simulator} type to run simulations, and the solver writer creates a \texttt{Solver} subtype to run computations offline, and a \texttt{Policy} subtype to execute a policy online.

In POMDPs.jl the term ``Belief'' is used to mean any structure that encodes the information needed to execute the policy.
For instance, if the policy is encoded as a set of alpha vectors, the belief takes its usual meaning as an explicit probability distribution over the states; for an online solver like POMCP, it must generate states for the tree search; and for a finite-state-machine policy like the one created by MCVI, it is simply the id of the current node.
An \texttt{Updater} in POMDPs.jl is an object that defines how information from new observations is integrated into the belief.
For example, if the belief is a probability distribution, the updater would apply Bayes rule or an approximation.
Since the belief is often closely related to the policy, the solver writer will often implement the \texttt{Updater}, however generic updaters such as particle filters are also available.
\Cref{fig:concepts} shows the three role concepts and some of the associated abstract types and interface functions.

\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.8\linewidth]{media/arch.pdf}
    \caption[POMDPs.jl concepts]{POMDPs.jl concepts. POMDPs.jl facilitates communication between people in three roles. The abstract types are shown beside each node and some of the interface functions are shown between the nodes. The arrows indicate which roles use code from which other roles.}
    \label{fig:concepts}
\end{figure}

\subsection{Interfaces}

The behavior of POMDPs.jl objects is defined by implementing methods of interface functions.
Implementing interface functions serves as an alternative to writing configuration files such as POMDPX files or specifications in purpose-built languages like RDDL~\cite{sanner2010rddl} in previous frameworks.
For example the problem writer may implement a method of the \texttt{reward} function that returns the reward given a problem instance, state and action.
Julia will call the correct \texttt{reward} method for the problem type based on its multiple dispatch system \cite{bezanson2017julia}.
Similarly, an \texttt{Updater} should have a corresponding \texttt{update} method that returns a new belief given an updater object, previous belief, action, and observation.
The complete interface is not listed here, but is available in the online documentation.

In POMDPs.jl, states, actions, observations, beliefs, and distributions can be represented by objects of any type as long as the appropriate interface methods are implemented.
This provides the flexibility needed to represent continuous or discrete problems.
Packages in the Julia ecosystem provide convenient and efficient types for common state representations, such as small fixed-size vectors.

One flexibility goal that has not been met by previous frameworks is support of both generative and explicit problem definitions.
For example, in APPL, all solvers can handle POMDPX problem specification for explicit definitions, but the MCVI and DESPOT solvers use different interfaces for generative problems, and there is no way to represent continuous problems explicitly.
POMDPs.jl overcomes this challenge by exposing both an explicit interface and generative interface that can be mixed.
If the necessary parts of the explicit interface are implemented for a problem, POMDPs.jl will automatically provide the generative interface functions for the problem.
The interface relationships are illustrated in \cref{fig:interfaces}.
Implementations of all of the interface functions are not strictly required; if the minimum set of functions used by a solver or simulator are implemented for a problem, then that solver or simulator will work with that problem.

\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.8\linewidth]{media/interfaces.pdf}
    \caption{POMDPs.jl interfaces}
    \label{fig:interfaces}
\end{figure}

Because of the interface's flexibility, expressing which interface functions a problem-writer should implement, giving helpful error messages, and even checking whether a sufficient portion of the interface has been implemented is a complex challenge.
For example, suppose a user intends to implement a complex problem that cannot easily be expressed with an explicit definition and intends to use a solver that only requires functions from the generative interface.
If POMDPs.jl advises this user to implement functions from the explicit interface, he or she will conclude that expressing the problem is difficult or impossible.
This complexity drove the development of an interface and framework for dynamically specifying requirements and dependencies and generating helpful reports for users.
In this requirements framework, built with Julia's powerful metaprogramming features, solver and simulator writers declare the requirements for their algorithm, which may be based on solver options, and problem writers can check which of the requirements have been satisfied by their problem implementation.
Examples of the output of this system are shown in \cref{fig:requirements}.

\begin{figure}[htpb]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{media/requirements_info_new.png}
    \end{center}
    \caption{New problem with no methods}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
    \begin{center}
        \includegraphics[width=\textwidth]{media/requirements_info_gw.png}
    \end{center}
    \caption{Fully implemented problem}
    \end{subfigure}
     
    \caption[POMDPs.jl requirements example]{POMDPs.jl requirements example output for the value iteration solver}
    \label{fig:requirements}
\end{figure}

\section{Examples}

This section presents simple examples illustrating implementations of the concepts in~\cref{sec:concepts}, namely the problem, the solver, and the experiment. 

\lstset{escapechar=@,style=customjulia}

\subsection{Problem}

The problem defines the MDP or POMDP model to be solved.
%The user decides how to define the model components.
For this example, consider the Tiger POMDP example of \citet{kaelbling1998planning}.

\begin{lstlisting}
 struct TigerPOMDP <: POMDP{Symbol, Symbol, Symbol}
     p_correct::Float64 # probability of hearing the tiger correctly
     discount::Float64  # discount factor
 end
\end{lstlisting}
%
The \code{TigerPOMDP} type is a subtype of the abstract {\small\ttfamily POMDP} type 
The three parameters of \code{POMDP} denote the types used to represent the states, actions, and observations.
These can be any types including built-in Julia types or special-purpose user defined types.
Here \code{Symbol}s (interned strings) are used for the sake of readability, but \code{Bool}s, \code{Int}s, or a custom enumeration could also easily be used.
% In this case, since the tiger is behind one of two doors, the state is represented by the native \code{Bool}.
% Similarly, since there are three actions, an \code{Int} is used to represent each, and a \code{Bool} represents each observation.
% The constants make the code easier to read.
 
The problem behavior is defined by implementing new methods of the functions in the POMDPs.jl interface.
For example, the function below returns the observation distribution for the Tiger POMDP given an action and state.

\begin{lstlisting}
 function POMDPs.observation(pomdp::TigerPOMDP, a::Symbol, sp::Symbol)
     pc = pomdp.p_correctly
     if a == :listen
         if sp == :tiger_left
             p = pomdp.p_correct
         else
             p = 1.0 - pomdp.p_correct
         end
     else
         p = 0.5
     end
     return SparseCat([:tiger_left, :tiger_right], [p, 1.0-p])
 end
\end{lstlisting}

The \code{SparseCat} object returned by this method is provided by the POMDPToolbox package, represents a (potentially sparse) categorical distribution over a list of objects.
Other code can randomly sample from the \code{SparseCat} distribution, query its probability distribution, and efficiently iterate over the members with nonzero probability.

Since the state in the Tiger POMDP never changes, the transition dynamics can be expressed concisely as
\begin{lstlisting}
 function POMDPs.transition(pomdp::TigerPOMDP, s::Symbol, a::Symbol)
     if a == :listen
         return SparseCat([s], [1.0]) 
     else # a looking action - the problem finishes
         return SparseCat([:done], [1.0])
     end
 end
\end{lstlisting}

The entire problem definition contains several more methods, including \code{reward}, \code{actions}, \code{discount}, \code{isterminal}, etc.

\subsection{Solver} 

A solver implementation requires between one and three type definitions: a \code{Solver} that contains the parameters that define solver behavior, often a \code{Policy} that defines a mapping from beliefs to actions, and sometimes an \code{Updater} if the belief is closely linked to how the policy functions.
Some example code for the QMDP~\citep{littman1995} solution method is shown below.

QMDP works by running value iteration on the fully observable MDP at the core.
In the \code{solve} function, partially listed below, the POMDPs.jl functions which will have methods for the particular POMDP being solved are called.
Once value iteration has completed, an \code{AlphaVectorPolicy} from POMDPToolbox.jl is returned.
The ellipses indicate code that has been left out for the sake of brevity.

\begin{lstlisting}
 function POMDPs.solve(solver::QMDPSolver, pomdp::POMDP)
     ...
     for i in 1:solver.max_iterations
         ...
         for (istate,s) in enumerate(states)
             if isterminal(mdp, s)
                 util[istate] = 0.0
                 ...
             else
                 ...
                 for a in iterator(actions(pomdp, s))
                     dist = transition(mdp, s, a)
                     u = 0.0
                     for (sp, p) in weighted_iterator(dist)
                         r = reward(pomdp, s, a, sp)
                         isp = state_index(pomdp, sp)
                         u += p * (r + discount(pomdp) * util[isp])
                 ...
     return AlphaVectorPolicy(qvalues)
 end
\end{lstlisting}

\subsection{Simulator}

POMDP Solution algorithms are typically evaluated by running Monte Carlo simulations.
A \code{Simulator} calls POMDPs.jl functions defined for the solver and the problem to run a simulation and return the desired statistics from that simulation.
For example, the experimenter might create a simulator type, {\ttfamily Sim}, and a corresponding {\ttfamily simulate} function (an important part of the main loop is shown below).
\begin{lstlisting}
 function simulate(sim::Sim, pomdp::POMDP, policy::Policy, updater::Updater, initial_dist)
    ...
    for t in 1:sim.max_steps
        a = action(policy, b)
        sp = rand(sim.rng, transition(pomdp, s, a))
        r_total += discount(pomdp)^t*reward(pomdp, s, a, sp)
        o = rand(sim.rng, observation(pomdp, s, a, sp))
        b = update(updater, b, a, o)
        ...
\end{lstlisting}

With the examples above and the appropriate additional methods defined, a simulation can then be run as follows: 
\begin{lstlisting}
 pomdp = TigerPOMDP()           # initialize the tiger problem
 solver = QMDPSolver()          # initialize QMDP solver
 policy = solve(solver, pomdp)  # compute a policy
 r = simulate(Sim(), pomdp, policy, updater(policy), DiscreteBelief(2))
\end{lstlisting}

\section{Summary}

By using the leverage of the Julia programming language, POMDPs.jl provides an unprecedented level of flexibility for expressing and solving POMDPs. It is being used by other researchers to investigate topics as diverse as GPS jammer detection by drones and cancer screening recommendations, along with numerous student projects for a course taught at Stanford.

\todo{See if I can cite some things}

However, there is still much work to be done.
First, for the simplest examples, POMDPs.jl is a rather clumsy interface in that it requires methods to be implemented to define behavior.
Some of the best interfaces for expressing mathematical optimization problems, such as JuMP~\cite{dunning2017jump} and CVX~\cite{grant2014cvx}, have concise, declarative interfaces that can express problems in a few lines of code and be easily interpreted by looking at one page for a short time.
The POMDP domain is much more diverse and complex than the optimization domains addressed by these packages, but a concise declarative interface that can represent a subset of POMDPs would be very helpful in the education mission of POMDPs.jl.

Second, many of the solvers are far from achieving the full performance potential of the algorithms that they implement.
Since most modern hardware performance increases are due to parallelism rather than single-process speed increases, one of the most important factors in speeding up solver code is parallel implementation.
Though Julia has built-in tools for parallel processing, only a few of the solvers have parallel capabilities because many of the important factors in efficient parallelism, such as proper cache usage, have many pitfalls.
An investment of effort into parallelizing solver code would make the POMDPs.jl ecosystem much more useful.
